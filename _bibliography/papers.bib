---
---

@article{uu_quest,
  abbr={ICML-UDL 2020},
  title={QUEST for MEDISYN: Quasi-norm based Uncertainty ESTimation for MEDical Image SYNthesis},
  author={Uddeshya, Upadhyay* and Viswanath P., Sudarshan* and Suyash, Awate},
  abstract={Uncertainty quantification in medical imaging is
  critical for clinical translation of deep learning-
  based methods. Modality propagation within the
  context of medical imaging is a problem of inter-
  est, both across as well as within modalities. For
  magnetic resonance imaging (MRI), often, multi-
  contrast MRI images are acquired for improved
  diagnosis and prognosis. In this work, we focus
  on the synthesis of T2w MRI images from T1w
  MRI images. Prior works used generative adver-
  sarial networks (GANs), but lack (i) uncertainty
  quantification, (ii) evaluating the robustness of
  the network to out-of-distribution data (common
  in medical imaging). We propose a robust GAN
  framework that incorporates uncertainty quantifi-
  cation using quasi-norm based penalties, and also
  show the efficacy of the method on unseen sys-
  temic and physiological perturbations on a large
  publicly available multimodal MRI dataset.},
  year={2020},
  pdf={example_pdf.pdf},
}

@article{uu_compactresl,
  abbr={ISBI 2020},
  author={Uddeshya, Upadhyay and Biplap, Banerjee},
  title={Compact Representation Learning Using Class Specific Convolution Coders-Application to Medical Image Classification}, 
  year={2020},
  pages={1266--1270},
  abstract={Medical image classification using deep learning techniques rely on highly curated datasets, which are difficult and expensive to obtain in real world due significant expertise required to annotate the dataset. We propose a novel framework called Class Specific Convolutional Coders (CSCC) to tackle the problem of learning highly discriminative, compact and non-redundant feature space from a relatively small amount of labelled images. We design separate attention-driven convolution network based feature extractors for the categories. These feature learning modules are further intuitively combined so as to make the whole image recognition system end-to-end trainable. Results on different medical image classification tasks show the advantages of our contributions, where our proposed methods outperforms the benchmark supervised deep convolutional networks (CNNs) trained from scratch.},
  url       = {https://doi.org/10.1109/ISBI45749.2020.9098415},
  doi       = {10.1109/ISBI45749.2020.9098415},
  pdf={example_pdf.pdf},
  publisher={2020 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2020)}
}

@article{uu_qegan,
  abbr={MICCAI 2019},
  title={A Mixed-Supervision Multilevel {GAN} Framework for Image Quality Enhancement},
  author={Uddeshya, Upadhyay and Suyash, Awate},
  pages     = {556--564},
  abstract={Deep neural networks for image quality enhancement typically need large quantities of highly-curated training data comprising pairs of low-quality images and their corresponding high-quality images. While high-quality image acquisition is typically expensive and time-consuming, medium-quality images are faster to acquire, at lower equipment costs, and available in larger quantities. Thus, we propose a novel generative adversarial network (GAN) that can leverage training data at multiple levels of quality (e.g., high and medium quality) to improve performance while limiting costs of data curation. We apply our mixed-supervision GAN to (i) super-resolve histopathology images and (ii) enhance laparoscopy images by combining super-resolution and surgical smoke removal. Results on large clinical and pre-clinical datasets show the benefits of our mixed-supervision GAN over the state of the art.},
  year      = {2019},
  url       = {https://doi.org/10.1007/978-3-030-32254-0\_62},
  doi       = {10.1007/978-3-030-32254-0\_62},
  pdf={example_pdf.pdf},
  publisher={Medical Image Computing and Computer Assisted Intervention - {MICCAI} 2019, Springer}
}

@article{uu_spindlemri,
  abbr={IJCNN 2019},
  author={Uddeshya, Upadhyay and Badrinath, Singhal and Meenakshi, Singh},
  title={Spinal Stenosis Detection in MRI using Modular Coordinate Convolutional Attention Networks}, 
  year={2019},
  pages={1--8},
  abstract={Spinal stenosis is a condition in which a portion of spinal canal narrows and exerts pressure on nerves that travel through it causing pain and numbness that might require surgery. This narrowing can be caused by pathologies in bony structures (vertebrae) or soft tissue structures (intervertebral discs) that comprise the spine. Radiography, particularly Magnetic Resonance Imaging (MRI) is the modality of choice to evaluate stenosis and intervertebral disc pathology. Radiologists examine axial MRI scans at various levels along the spine to detect stenosis. Further, they evaluate the diameters of spinal canal and bulging in nearby discs which can indicate narrowing and compression on nerves. Hence measuring various diameters in a scan is a crucial step in diagnosis. However, affected regions occupy a very small fraction of the scan and there is virtually no room for error as a deviation of few pixels will also lead to discrepancies in measured and original lengths which makes it a very difficult and laborious task to measure the length of such intricate structures accurately. We propose a novel deep learning based solution to tackle this problem. Our method attempts to solve it in two independent modules and allows us to make prediction on the enlarged section of the scan which also makes it easier to measure various lengths. Human radiologists focus on certain parts of the scan rather than attending to the entire scan which largely consists of irrelevant background. We design our modular approach to mimic this attention mechanism. Both of our modules are built using coordinate convolutional networks, we also perform the comparison with baseline and empirically demonstrate superiority of our approach.},
  url = {https://doi.org/10.1109/IJCNN.2019.8852085},
  doi = {10.1109/IJCNN.2019.8852085},
  pdf={example_pdf.pdf},
  publisher={International Joint Conference on Neural Networks, {IJCNN} 2019 Budapest}
}

@article{uu_rsrgan,
  abbr={ISBI 2019},
  author={Uddeshya, Upadhyay and Suyash, Awate},
  title={Robust Super-Resolution Gan, with Manifold-Based and Perception Loss}, 
  year={2019},
  pages={1372-1376},
  abstract={Super-resolution using deep neural networks typically relies on highly curated training sets that are often unavailable in clinical deployment scenarios. Using loss functions that assume Gaussian-distributed residuals makes the learning sensitive to corruptions in clinical training sets. We propose novel loss functions that are robust to corruptions in training sets by modeling heavy-tailed non-Gaussian distributions on the residuals. We propose a loss based on an autoencoder-based manifold-distance between the super-resolved and high-resolution images, to reproduce realistic textural content in super-resolved images. We propose to learn to super-resolve images to match human perceptions of structure, luminance, and contrast. Results on a large clinical dataset shows the advantages of each of our contributions, where our framework improves over the state of the art.},
  doi={10.1109/ISBI.2019.8759375},
  url={https://ieeexplore.ieee.org/abstract/document/8759375},
  pdf={example_pdf.pdf},
  publisher={2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)}
}
